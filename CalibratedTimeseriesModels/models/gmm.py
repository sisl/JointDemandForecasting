# Gaussian mixture model

from CalibratedTimeseriesModels.abstractmodels import *
import torch
import numpy as np

class GaussianMixtureModel(GenerativePredictiveModel):
    
    def __init__(self, n_components, n_features, eps=1e-6):
        """
        Args:
            n_components:   int
            n_features:     int
            eps:            float
        """
        super(GaussianMixtureModel, self).__init__()
        
        self.eps = eps
        self.n_components = n_components
        self.n_features = n_features
        self.log_likelihood = -np.inf

        self.mu_init = mu_init
        self.var_init = var_init
 
        self.mu = torch.nn.Parameter(torch.randn(1, self.n_components, self.n_features), requires_grad=False)
        self.var = torch.nn.Parameter(torch.ones(1, self.n_components, self.n_features), requires_grad=False)
        self.pi = torch.nn.Parameter(torch.Tensor(1, self.n_components, 1), requires_grad=False).fill_(1./self.n_components)

        self.params_fitted = False

    def fit(self, x, delta=1e-3, n_iter=100):
        """
        Args:
            n_iter (int)
            delta (float)
        """
        if not self.params_fitted:
            self._init_params()

        if len(x.size()) == 2:
            x = x.unsqueeze(1).expand(x.size(0), self.n_components, x.size(1))

        i = 0
        j = np.inf

        while (i <= n_iter) and (j >= delta):
            log_likelihood_old = self.log_likelihood
            mu_old = self.mu
            var_old = self.var

            self.__em(x)
            self.log_likelihood = self.__score(self.pi, self.__p_k(x, self.mu, self.var))

            if (self.log_likelihood.abs() == float("Inf")) or (self.log_likelihood == float("nan")):
                self.__init__(self.n_components, self.n_features)

            i += 1
            j = self.log_likelihood - log_likelihood_old

            if j <= delta:
                self.__update_mu(mu_old)
                self.__update_var(var_old)

        self.params_fitted = True

    def predict(self, x, probs=True):
        """
        Assigns input data to one of the mixture components by evaluating the likelihood under each.
        Args:
            x (torch.Tensor): (n, d) or (n, k, d)
            probs (bool): If probs=True returns normalized probabilities of class membership.
        Returns:
            y (torch.LongTensor): (n)
        """
        if len(x.size()) == 2:
            x = x.unsqueeze(1).expand(x.size(0), self.n_components, x.size(1))
        p_k = self.__p_k(x, self.mu, self.var)
        if probs:
            return p_k / (p_k.sum(1, keepdim=True) + self.eps)
        else:
            _, predictions = torch.max(p_k, 1)
            return torch.squeeze(predictions).type(torch.LongTensor)

    def score_samples(self, x):
        """
        Computes log-likelihood of data (x) under the current model.
        Args:
            x (torch.Tensor): (n, d) or (n, k, d)
        Returns:
            score (torch.LongTensor): (n)
        """
        if len(x.size()) == 2:
            x = x.unsqueeze(1).expand(x.size(0), self.n_components, x.size(1))
        score = self.__score(self.pi, self.__p_k(x, self.mu, self.var), sum_data=False)
        return score

    def __p_k(self, x, mu, var):
        """
        Returns a tensor with dimensions (n, k, 1) indicating the likelihood of data belonging to the k-th Gaussian.
        Args:
            x (torch.Tensor): (n, k, d)
            mu (torch.Tensor): (1, k, d)
            var (torch.Tensor): (1, k, d)
        Returns:
            p_k (torch.Tensor): (n, k, 1)
        """
        mu = mu.expand(x.size(0), self.n_components, self.n_features)
        var = var.expand(x.size(0), self.n_components, self.n_features)
        
        exponent = torch.exp(-.5 * torch.sum((x - mu) * (x - mu) / var, 2, keepdim=True))
        prefactor = torch.rsqrt(((2. * np.pi) ** self.n_features) * torch.prod(var, dim=2, keepdim=True) + self.eps)

        return prefactor * exponent

    def __e_step(self, pi, p_k):
        """
        Computes weights that indicate the probability that a data point was generated by one of the k mixture components.    
        Args:
            pi (torch.Tensor): (1, k, 1)
            p_k (torch.Tensor): (n, k, 1)
        Returns:
            weights (torch.Tensor): (n, k, 1)
        """

        weights = pi * p_k
        return torch.div(weights, torch.sum(weights, 1, keepdim=True) + self.eps)


    def __m_step(self, x, weights):
        """
        Updates the parameters.
        Args:
            x (torch.Tensor): (n, k, d)
            weights (torch.Tensor): (n, k, 1)
        Returns:
            pi_new (torch.Tensor): (1, k, 1)
            mu_new (torch.Tensor): (1, k, d)
            var_new (torch.Tensor): (1, k, d)
        """
        n_k = torch.sum(weights, 0, keepdim=True)
        pi_new = torch.div(n_k, torch.sum(n_k, 1, keepdim=True) + self.eps)
        mu_new = torch.div(torch.sum(weights * x, 0, keepdim=True), n_k + self.eps)
        var_new = torch.div(torch.sum(weights * (x - mu_new) * (x - mu_new), 0, keepdim=True), n_k + self.eps)

        return pi_new, mu_new, var_new

    def __em(self, x):
        """
        Performs one iteration of the expectation-maximization algorithm.
        Args:
            x (torch.Tensor): (n, k, d)
        """
        weights = self.__e_step(self.pi, self.__p_k(x, self.mu, self.var))
        pi_new, mu_new, var_new = self.__m_step(x, weights)

        self.__update_pi(pi_new)
        self.__update_mu(mu_new)
        self.__update_var(var_new)

    def __score(self, pi, p_k, sum_data=True):
        """
        Computes the log-likelihood of the data under the model.
        Args:
            pi (torch.Tensor): (1, k, 1)
            p_k (torch.Tensor): (n, k, 1)
        """
        weights = pi * p_k
        if sum_data:
            return torch.sum(torch.log(torch.sum(weights, 1) + self.eps))
        else:
            return torch.log(torch.sum(weights, 1) + self.eps)

    def __update_mu(self, mu):
        """
        Args:
            mu (torch.FloatTensor): (1, k, d)
        """
        if mu.size() == (self.n_components, self.n_features):
            self.mu = mu.unsqueeze(0)
        elif mu.size() == (1, self.n_components, self.n_features):
            self.mu.data = mu

    def __update_var(self, var):
        """
        Args:
            var (torch.FloatTensor): (1, k, d)
        """
        if var.size() == (self.n_components, self.n_features):
            self.var = var.unsqueeze(0)
        elif var.size() == (1, self.n_components, self.n_features):
            self.var.data = var

    def __update_pi(self, pi):
        """
        Args:
            pi (torch.FloatTensor): (1, k, 1)
        """
        self.pi.data = pi
        
       